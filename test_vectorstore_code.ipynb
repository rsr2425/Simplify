{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanrodriguez/src/Simplify/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import nltk\n",
    "import logging\n",
    "import uuid\n",
    "\n",
    "from typing import Optional, List\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEMS_REFERENCE_COLLECTION_NAME = \"problems_reference_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_qdrant_client_instance: Optional[QdrantClient] = None\n",
    "\n",
    "def get_qdrant_client():\n",
    "    global _qdrant_client_instance\n",
    "\n",
    "    if _qdrant_client_instance is None:\n",
    "        QDRANT_URL = \"https://f920e9b6-c14c-40e4-9fbe-a2aabf26e2b5.us-east-1-0.aws.cloud.qdrant.io\"\n",
    "        QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.lWz54tW8xpFc85mqDRgmj_luvKbEcJhK6hkLVNMEKsk\"\n",
    "\n",
    "        _qdrant_client_instance = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "    return _qdrant_client_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_EMBEDDING_MODEL_ID = \"text-embedding-3-small\"\n",
    "embedding_model = OpenAIEmbeddings(model=DEFAULT_EMBEDDING_MODEL_ID)\n",
    "\n",
    "client = get_qdrant_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='problems_reference_collection'), CollectionDescription(name='star_charts')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_info = client.get_collection(PROBLEMS_REFERENCE_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_info.vectors_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_documents(\n",
    "    source: str, documents: List[Document], collection_name: str, client: QdrantClient\n",
    "):\n",
    "    client.add(\n",
    "        collection_name=collection_name,\n",
    "        documents=documents,\n",
    "        ids=[str(uuid.uuid4()) for _ in documents],\n",
    "        payload={\"source\": source},\n",
    "    )\n",
    "\n",
    "def get_docs(embedding_model):\n",
    "        # Create static/data directory if it doesn't exist\n",
    "        os.makedirs(\"static/data\", exist_ok=True)\n",
    "\n",
    "        # Download and save the webpage if it doesn't exist\n",
    "        html_path = \"static/data/langchain_rag_tutorial.html\"\n",
    "        if not os.path.exists(html_path):\n",
    "            url = \"https://python.langchain.com/docs/tutorials/rag/\"\n",
    "            response = requests.get(url)\n",
    "            with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response.text)\n",
    "\n",
    "        # Load HTML files from static/data directory\n",
    "        loader = DirectoryLoader(\"static/data\", glob=\"*.html\")\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=200\n",
    "        )\n",
    "        split_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "        return split_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_docs(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_info.config.params.vectors.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(\"test_collection\")\n",
    "client.delete_collection(PROBLEMS_REFERENCE_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.models import VectorParams, Distance\n",
    "client.create_collection(\n",
    "    PROBLEMS_REFERENCE_COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=PROBLEMS_REFERENCE_COLLECTION_NAME,\n",
    "    embeddings=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "def get_document_hash_as_uuid(doc):\n",
    "    # First get the hash of the content\n",
    "    content_hash = hashlib.sha256(doc.page_content.encode()).hexdigest()\n",
    "    \n",
    "    # Convert the first 32 characters of the hash (16 bytes) to UUID\n",
    "    # UUID requires exactly 16 bytes (32 hex characters)\n",
    "    uuid_from_hash = uuid.UUID(content_hash[:32])\n",
    "    \n",
    "    return str(uuid_from_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['794f95e2-bee6-e5cc-ed64-7c6fe1aef022',\n",
       " '6fa4f018-af75-fd5c-a90e-d460b30972ef',\n",
       " 'ad483089-34a0-5f96-0588-5e288b5964b5',\n",
       " 'b3e2ac2a-35e0-58b3-d5f5-d98929d6caab',\n",
       " '4cf742c8-601a-65f1-cfd6-79876b068503',\n",
       " 'c74bc126-5e9f-d70c-c0a0-3ec91ea248d0',\n",
       " '6366496e-5133-00f3-36d5-cdd91b479aa5',\n",
       " 'c9e530f6-b567-ffc5-cd44-781022dfcfc6',\n",
       " '512f428b-05a7-920b-c2a9-1211406bb7ed',\n",
       " '8a092ec4-c4fd-c234-2b7c-bb2e23cbe973',\n",
       " '54813989-564e-3b6c-3ef8-451f33cdbf6b',\n",
       " 'e0611fe9-cade-2e43-6966-82d7a26c0278',\n",
       " '1eebf00f-a10a-0d73-982e-cd8844945c18',\n",
       " '02002419-ec33-775d-2b85-bc53e12aa3cf',\n",
       " '62a197cd-0e46-e846-b7dc-fbd0dc210a31',\n",
       " 'aa1618aa-b1b1-3b19-e356-81b8b21affd4',\n",
       " 'db4474e5-7265-f6e5-e242-bca78d1503a1',\n",
       " 'bebdc4ad-f0a3-6480-5c82-dc8f0ace870b',\n",
       " '6dc203ca-380d-a452-84cd-3ee0abdd47b5',\n",
       " 'fe66ef26-24a3-199c-ba07-3a068a4b1c75',\n",
       " '6cb951d3-12c4-0614-a07e-4ac3c4b9b52f',\n",
       " 'f98f92b9-6d1f-226a-eed7-656edc04db79',\n",
       " 'ccfef227-20e2-bf29-e740-f66f5e376b72',\n",
       " 'e53a74e8-118d-2d42-78ed-d6ea3ad93201',\n",
       " '9772a884-e0b8-8d73-c464-17e839d691a8',\n",
       " 'dc51dd9c-2467-e0dd-c17a-4f3947770146',\n",
       " '6f1523ed-c6b0-62ba-3261-05f993373adb',\n",
       " '97bad942-3a69-447f-d384-9b9a60f9cf88',\n",
       " '1826ed11-0cff-7ab0-4137-4c17ddd9e7fc',\n",
       " '3f71153e-d378-59d1-03d8-7f1bbe15e4c0',\n",
       " 'c17ea483-30a4-014b-c42f-7c6c44b7b47a',\n",
       " '986c2383-4509-0f92-3834-aeea851a216d',\n",
       " '4164df32-97b3-c1f3-ae38-56008f47c435',\n",
       " '3f0d297f-f62a-a8c0-8d8d-b226788f3a40',\n",
       " '7c4bee9b-93ad-26bb-e49d-770e03276add',\n",
       " '7c211878-b398-83a5-90ce-c7839e7d88d1',\n",
       " '2ccb136c-496b-9e5b-a388-57c1c018e5cb',\n",
       " 'b07a6e2e-05e6-550f-a2db-ade353284be5',\n",
       " '44c41257-7a12-83da-8f44-d7e9b1968d45',\n",
       " '638ab06e-5ac1-134e-ded3-af6536a2b04d',\n",
       " 'a2fb7256-e90a-169f-1cc3-7932b73f0cba',\n",
       " '12ee5cfe-be76-be09-a486-ca4252f5f7cc',\n",
       " '2b38415a-1f29-8cda-8625-7d0b0a1c8c26',\n",
       " 'a377526c-aee9-a842-a990-7f2ccbc7a644',\n",
       " '686ad547-a6ba-8187-22c9-5c312575713a',\n",
       " 'ebebc277-7ba6-7b8b-0368-efee03ccc2d7',\n",
       " '2d3b4ed2-70ec-4118-c800-b6f7a48f7b81',\n",
       " 'b905ba7d-7497-ec41-729b-4b343c98db2c',\n",
       " '299f6d65-39b1-3af4-0bf2-f7fee062f6e2',\n",
       " 'fd62bfd1-9a06-40ee-1ede-0590e9de85dc']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(\n",
    "    documents=docs,\n",
    "    ids=[get_document_hash_as_uuid(doc) for doc in docs],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'static/data/langchain_rag_tutorial.html'}, page_content='Tutorials\\n\\nBuild a Retrieval Augmented Generation (RAG) App: Part 1\\n\\nBuild a Retrieval Augmented Generation (RAG) App: Part 1\\n\\nOne of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation, or RAG.\\n\\nThis is a multi-part tutorial:\\n\\nPart 1 (this guide) introduces RAG and walks through a minimal implementation.\\n\\nPart 2 extends the implementation to accommodate conversation-style interactions and multi-step retrieval processes.')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=None, indexed_vectors_count=0, points_count=100, segments_count=2, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None), payload_schema={})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_reference_collection = client.get_collection(PROBLEMS_REFERENCE_COLLECTION_NAME)\n",
    "problem_reference_collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vectorstore.similarity_search(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'static/data/langchain_rag_tutorial.html',\n",
       " '_id': '7072fce1-91f3-43f8-bd1c-2a2efebf258c',\n",
       " '_collection_name': 'problems_reference_collection'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_document_metadata(doc: Document, **additional_metadata) -> Document:\n",
    "    \"\"\"Add additional metadata to a document while preserving original metadata.\"\"\"\n",
    "    doc.metadata.update(additional_metadata)\n",
    "    return doc\n",
    "\n",
    "enriched_docs = [\n",
    "            enrich_document_metadata(\n",
    "                doc,\n",
    "                title=\"LangChain RAG Tutorial\",\n",
    "                # type=\"tutorial\",\n",
    "                source_url=\"https://python.langchain.com/docs/tutorials/rag/\",\n",
    "                description=\"Official LangChain tutorial on building RAG applications\",\n",
    "            ) for doc in docs\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'static/data/langchain_rag_tutorial.html', 'title': 'LangChain RAG Tutorial', 'type': 'tutorial', 'source_url': 'https://python.langchain.com/docs/tutorials/rag/', 'description': 'Official LangChain tutorial on building RAG applications'}, page_content='Tutorials\\n\\nBuild a Retrieval Augmented Generation (RAG) App: Part 1\\n\\nBuild a Retrieval Augmented Generation (RAG) App: Part 1\\n\\nOne of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation, or RAG.\\n\\nThis is a multi-part tutorial:\\n\\nPart 1 (this guide) introduces RAG and walks through a minimal implementation.\\n\\nPart 2 extends the implementation to accommodate conversation-style interactions and multi-step retrieval processes.')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['794f95e2-bee6-e5cc-ed64-7c6fe1aef022',\n",
       " '6fa4f018-af75-fd5c-a90e-d460b30972ef',\n",
       " 'ad483089-34a0-5f96-0588-5e288b5964b5',\n",
       " 'b3e2ac2a-35e0-58b3-d5f5-d98929d6caab',\n",
       " '4cf742c8-601a-65f1-cfd6-79876b068503',\n",
       " 'c74bc126-5e9f-d70c-c0a0-3ec91ea248d0',\n",
       " '6366496e-5133-00f3-36d5-cdd91b479aa5',\n",
       " 'c9e530f6-b567-ffc5-cd44-781022dfcfc6',\n",
       " '512f428b-05a7-920b-c2a9-1211406bb7ed',\n",
       " '8a092ec4-c4fd-c234-2b7c-bb2e23cbe973',\n",
       " '54813989-564e-3b6c-3ef8-451f33cdbf6b',\n",
       " 'e0611fe9-cade-2e43-6966-82d7a26c0278',\n",
       " '1eebf00f-a10a-0d73-982e-cd8844945c18',\n",
       " '02002419-ec33-775d-2b85-bc53e12aa3cf',\n",
       " '62a197cd-0e46-e846-b7dc-fbd0dc210a31',\n",
       " 'aa1618aa-b1b1-3b19-e356-81b8b21affd4',\n",
       " 'db4474e5-7265-f6e5-e242-bca78d1503a1',\n",
       " 'bebdc4ad-f0a3-6480-5c82-dc8f0ace870b',\n",
       " '6dc203ca-380d-a452-84cd-3ee0abdd47b5',\n",
       " 'fe66ef26-24a3-199c-ba07-3a068a4b1c75',\n",
       " '6cb951d3-12c4-0614-a07e-4ac3c4b9b52f',\n",
       " 'f98f92b9-6d1f-226a-eed7-656edc04db79',\n",
       " 'ccfef227-20e2-bf29-e740-f66f5e376b72',\n",
       " 'e53a74e8-118d-2d42-78ed-d6ea3ad93201',\n",
       " '9772a884-e0b8-8d73-c464-17e839d691a8',\n",
       " 'dc51dd9c-2467-e0dd-c17a-4f3947770146',\n",
       " '6f1523ed-c6b0-62ba-3261-05f993373adb',\n",
       " '97bad942-3a69-447f-d384-9b9a60f9cf88',\n",
       " '1826ed11-0cff-7ab0-4137-4c17ddd9e7fc',\n",
       " '3f71153e-d378-59d1-03d8-7f1bbe15e4c0',\n",
       " 'c17ea483-30a4-014b-c42f-7c6c44b7b47a',\n",
       " '986c2383-4509-0f92-3834-aeea851a216d',\n",
       " '4164df32-97b3-c1f3-ae38-56008f47c435',\n",
       " '3f0d297f-f62a-a8c0-8d8d-b226788f3a40',\n",
       " '7c4bee9b-93ad-26bb-e49d-770e03276add',\n",
       " '7c211878-b398-83a5-90ce-c7839e7d88d1',\n",
       " '2ccb136c-496b-9e5b-a388-57c1c018e5cb',\n",
       " 'b07a6e2e-05e6-550f-a2db-ade353284be5',\n",
       " '44c41257-7a12-83da-8f44-d7e9b1968d45',\n",
       " '638ab06e-5ac1-134e-ded3-af6536a2b04d',\n",
       " 'a2fb7256-e90a-169f-1cc3-7932b73f0cba',\n",
       " '12ee5cfe-be76-be09-a486-ca4252f5f7cc',\n",
       " '2b38415a-1f29-8cda-8625-7d0b0a1c8c26',\n",
       " 'a377526c-aee9-a842-a990-7f2ccbc7a644',\n",
       " '686ad547-a6ba-8187-22c9-5c312575713a',\n",
       " 'ebebc277-7ba6-7b8b-0368-efee03ccc2d7',\n",
       " '2d3b4ed2-70ec-4118-c800-b6f7a48f7b81',\n",
       " 'b905ba7d-7497-ec41-729b-4b343c98db2c',\n",
       " '299f6d65-39b1-3af4-0bf2-f7fee062f6e2',\n",
       " 'fd62bfd1-9a06-40ee-1ede-0590e9de85dc']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(\n",
    "    documents=enriched_docs,\n",
    "    ids=[get_document_hash_as_uuid(doc) for doc in docs],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vectorstore.similarity_search(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'static/data/langchain_rag_tutorial.html', 'title': 'LangChain RAG Tutorial', 'type': 'tutorial', 'source_url': 'https://python.langchain.com/docs/tutorials/rag/', 'description': 'Official LangChain tutorial on building RAG applications', '_id': '2d3b4ed2-70ec-4118-c800-b6f7a48f7b81', '_collection_name': 'problems_reference_collection'}, page_content='code writing mode with a different system message.\\\\nSystem message:\\'), Document(id=\\'1fcc2736-30f4-4ef6-90f2-c64af92118cb\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'start_index\\': 35127, \\'section\\': \\'end\\'}, page_content=\\'\"content\": \"You will get instructions for code to write.\\\\\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\\\\\n\\\\\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\\\\\n\\\\\\\\nThen you will output the content of each file including ALL code.\\\\\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\\\\\nFILENAME is the lowercase file name including')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if PROBLEMS_REFERENCE_COLLECTION_NAME exists. If not, create it.\n",
    "def check_collection_exists(collection_name):\n",
    "    return client.get_collection(collection_name) is not None\n",
    "\n",
    "if not check_collection_exists(PROBLEMS_REFERENCE_COLLECTION_NAME):\n",
    "    client.create_collection(\n",
    "        PROBLEMS_REFERENCE_COLLECTION_NAME,\n",
    "        vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
